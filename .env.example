# ========================================
# Kube-OVN-LangGraph-Checker 配置文件
# ========================================
# 复制此文件为 .env 并填入您的实际配置
# 命令: cp .env.example .env
# ========================================

# ------------------------------------------------------------------------------
# 核心配置 (必需)
# ------------------------------------------------------------------------------

# LLM API 密钥
# --------
# 获取方式:
# - OpenAI: https://platform.openai.com/api-keys
# - Azure OpenAI: 在 Azure Portal 创建 OpenAI 资源后获取
# - DeepSeek: https://platform.deepseek.com/
# - 智谱 AI: https://open.bigmodel.cn/
# - 本地 Ollama: 无需 API Key，设置 OPENAI_API_BASE 为 localhost 地址
OPENAI_API_KEY=your-api-key-here

# ------------------------------------------------------------------------------
# LLM 服务配置 (可选)
# ------------------------------------------------------------------------------

# 自定义 API 端点
# --------
# 用于兼容 OpenAI API 的其他服务
# 留空则使用默认的 OpenAI API: https://api.openai.com/v1
#
# 支持的提供商示例:
# - Azure OpenAI: https://<resource-name>.openai.azure.com/
# - DeepSeek: https://api.deepseek.com/v1
# - 智谱 AI: https://open.bigmodel.cn/api/paas/v4/
# - 本地 Ollama: http://localhost:11434/v1
#OPENAI_API_BASE=https://api.openai.com/v1

# 模型名称
# --------
# 默认: gpt-4o
#
# 推荐配置:
# - 生产环境 (最佳质量): gpt-4o
# - 测试环境 (快速且便宜): gpt-4o-mini
# - 成本敏感: deepseek-chat, glm-4-flash
# - 本部署 (零成本): llama3, qwen2 (需要 Ollama)
#
# 注意: 不同提供商的模型名称不同
#LLM_MODEL=gpt-4o

# 温度参数
# --------
# 控制输出的随机性
# - 范围: 0.0 - 1.0
# - 默认: 0.0 (确定性输出，推荐)
# - 较高值 (>0.7): 更有创意但可能不稳定
#TEMPERATURE=0.0

# 最大诊断轮数
# --------
# Agent 收集证据和推理的最大轮数
# - 默认: 10
# - 大多数问题在 3-5 轮内解决
# - 复杂问题可能需要更多轮数
#MAX_ROUNDS=10

# ------------------------------------------------------------------------------
# Kubernetes 配置 (可选)
# ------------------------------------------------------------------------------

# Kubernetes 配置文件路径
# --------
# 默认: ~/.kube/config
# 如果使用多集群，可以指定特定的 kubeconfig 文件
#KUBECONFIG=/path/to/kubeconfig

# ------------------------------------------------------------------------------
# 日志和调试 (可选)
# ------------------------------------------------------------------------------

# 日志级别
# --------
# 控制输出详细程度
# - DEBUG: 详细的调试信息
# - INFO: 一般信息 (默认)
# - WARNING: 警告信息
# - ERROR: 仅错误信息
#LOG_LEVEL=INFO

# 诊断报告保存路径
# --------
# 自动保存诊断报告的目录
# 默认: 当前目录
#DIAGNOSIS_REPORT_DIR=./diagnosis_reports

# ------------------------------------------------------------------------------
# 性能调优 (可选)
# ------------------------------------------------------------------------------

# 工具执行超时时间 (秒)
# --------
# 单个工具执行的最大时间
# 默认: 30 秒
#TOOL_TIMEOUT=30

# 并发工具数量
# --------
# 同时执行的工具最大数量
# 默认: 5
# 较大值可能加快速度，但会增加资源消耗
#MAX_CONCURRENT_TOOLS=5

# ------------------------------------------------------------------------------
# 高级配置 (通常不需要修改)
# ------------------------------------------------------------------------------

# 禁用缓存
# --------
# 禁用 Kubernetes API 结果缓存
# 默认: false (启用缓存)
# 缓存可以显著提高性能，但在调试时可能需要禁用
#DISABLE_CACHE=false

# 缓存过期时间 (秒)
# --------
# Kubernetes API 结果的缓存时间
# 默认: 30 秒
#CACHE_TTL=30

# ------------------------------------------------------------------------------
# 配置示例 - 常见场景
# ------------------------------------------------------------------------------

# 场景 1: OpenAI (默认)
# ---------------------------------------
# OPENAI_API_KEY=sk-proj-xxxxx
# LLM_MODEL=gpt-4o

# 场景 2: Azure OpenAI
# ---------------------------------------
# OPENAI_API_KEY=xxxxx
# OPENAI_API_BASE=https://my-resource.openai.azure.com/
# LLM_MODEL=gpt-4o

# 场景 3: DeepSeek (经济型)
# ---------------------------------------
# OPENAI_API_KEY=sk-xxxxx
# OPENAI_API_BASE=https://api.deepseek.com/v1
# LLM_MODEL=deepseek-chat

# 场景 4: 智谱 AI (国内推荐)
# ---------------------------------------
# OPENAI_API_KEY=xxxxx
# OPENAI_API_BASE=https://open.bigmodel.cn/api/paas/v4/
# LLM_MODEL=glm-4-flash

# 场景 5: 本地 Ollama (离线/隐私)
# ---------------------------------------
# OPENAI_API_BASE=http://localhost:11434/v1
# LLM_MODEL=llama3:70b
# OPENAI_API_KEY=ollama  # Ollama 不需要真实 Key，但需要设置此变量

# ------------------------------------------------------------------------------
# 安全提示
# ------------------------------------------------------------------------------
# ⚠️  重要:
# 1. 永远不要将 .env 文件提交到版本控制系统
# 2. .env 文件已添加到 .gitignore
# 3. 定期轮换 API Key
# 4. 使用最小权限原则配置 API Key
# 5. 在生产环境考虑使用密钥管理服务 (如 HashiCorp Vault)
# ------------------------------------------------------------------------------
