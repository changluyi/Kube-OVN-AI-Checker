"""
LLM Agent åˆ†æå™¨ - å¤šè½®äº¤äº’æ¨¡å¼

è®¾è®¡ç†å¿µï¼š
- LLM ä½œä¸ºå¤§è„‘ï¼Œä¸»åŠ¨å†³ç­–éœ€è¦æ”¶é›†ä»€ä¹ˆèµ„æº
- æ”¶é›†å™¨ä½œä¸ºå·¥å…·ï¼Œä¾› LLM è°ƒç”¨
- æ”¯æŒå¤šè½®äº¤äº’ï¼Œæ¸è¿›å¼æ¨ç†
- åŸºäº LangGraph agent å®ç°
"""

import os
import json
from typing import Dict, Any, Optional, List
from pathlib import Path
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langgraph.errors import GraphRecursionError

from .tools import get_k8s_tools
from ..collectors import K8sResourceCollector
# è§„åˆ™ç³»ç»Ÿï¼ˆå…œåº•æœºåˆ¶ï¼‰
from ..knowledge.rules import get_all_rules, match_rule
# çŸ¥è¯†æ³¨å…¥å™¨ï¼ˆT0 è½»é‡çº§çŸ¥è¯†æ³¨å…¥ï¼‰
from ..knowledge.injector import KnowledgeInjector
# æ•°æ®è§£æå’Œæ ¼å¼åŒ–å·¥å…·
from ..utils.parsers import (
    parse_diagnosis_from_message,
    parse_text_diagnosis,
    format_tool_args,
    extract_output_error,
    extract_ai_message,
    make_json_safe,
    create_fallback_diagnosis
)


load_dotenv()


class LLMAgentAnalyzer:
    """LLM Agent åˆ†æå™¨ - å¤šè½®äº¤äº’æ¨¡å¼"""

    def __init__(
        self,
        model: str = "gpt-4o",
        temperature: float = 0.0,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        max_rounds: int = 10
    ):
        """
        åˆå§‹åŒ– Agent åˆ†æå™¨

        Args:
            model: OpenAI æ¨¡å‹åç§°
            temperature: æ¸©åº¦å‚æ•°
            api_key: OpenAI API key
            base_url: API base URL
            max_rounds: æœ€å¤§äº¤äº’è½®æ•° (é˜²æ­¢æ— é™å¾ªç¯)
        """
        self.model_name = model
        self.temperature = temperature
        self.max_rounds = max_rounds

        # åˆå§‹åŒ– LLM
        llm_kwargs = {
            "model": model,
            "temperature": temperature,
        }

        if api_key:
            llm_kwargs["api_key"] = api_key
        else:
            llm_kwargs["api_key"] = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
            if not llm_kwargs["api_key"]:
                raise ValueError(
                    "API_KEY not found in environment variables. "
                    "Please set LLM_API_KEY or OPENAI_API_KEY."
                )

        if not base_url:
            base_url = os.getenv("LLM_API_BASE")

        if base_url:
            llm_kwargs["base_url"] = base_url

        self.llm = ChatOpenAI(**llm_kwargs)

        # è·å–å·¥å…·
        self.tools = get_k8s_tools()

        # åˆ›å»º agent (æ·»åŠ  max_iterations é™åˆ¶é˜²æ­¢æ— é™å¾ªç¯)
        self.agent = create_react_agent(
            self.llm,
            self.tools,
            prompt=self._get_system_prompt_static(),
            debug=False  # å…³é—­è°ƒè¯•æ¨¡å¼,é¿å…è¾“å‡ºå¤§é‡äº‹ä»¶ä¿¡æ¯
        )

    def _get_system_prompt_static(self) -> str:
        """è·å–é™æ€ç³»ç»Ÿæç¤º (ç”¨äº agent åˆå§‹åŒ–)

        è¿™ä¸ªæç¤ºåœ¨ agent åˆ›å»ºæ—¶è®¾ç½®,ä½œä¸ºåŸºç¡€ç³»ç»Ÿæ¶ˆæ¯
        å…·ä½“çš„ T0 æ•°æ®å’Œç”¨æˆ·é—®é¢˜ä¼šåœ¨ diagnose æ—¶åŠ¨æ€æ·»åŠ 
        """
        return """ä½ æ˜¯ Kube-OVN ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚

## è¯Šæ–­ç­–ç•¥

### 1. æ¸è¿›å¼è¯Šæ–­æµç¨‹
```
T0 (10ç§’) â†’ å¿«é€Ÿå¥åº·æ£€æŸ¥,æ‰¾å‡ºä¸å¥åº·çš„ç»„ä»¶
   â†“
(æŒ‰éœ€)  â†’ æ·±åº¦åˆ†æ (OVN DBã€ç½‘ç»œæŠ“åŒ…ã€æ€§èƒ½æŒ‡æ ‡)
```

### 2. å…³é”®ç»„ä»¶è¯´æ˜

**æ ¸å¿ƒç»„ä»¶**:
- **kube-ovn-controller**: æ ¸å¿ƒæ§åˆ¶å™¨,è´Ÿè´£ç½‘ç»œç­–ç•¥ç¿»è¯‘å’Œ IPAM ç®¡ç†
- **kube-ovn-cni**: CNI æœåŠ¡å™¨,è´Ÿè´£æœ¬åœ°ç½‘ç»œé…ç½®
- **ovn-nb**: OVN åŒ—å‘æ•°æ®åº“,å­˜å‚¨é€»è¾‘ç½‘ç»œé…ç½®
- **ovn-sb**: OVN å—å‘æ•°æ®åº“,å­˜å‚¨ç‰©ç†ç½‘ç»œé…ç½®

**è¯Šæ–­ä¼˜å…ˆçº§**:
1. Controller æ—¥å¿— - æŸ¥çœ‹æ§åˆ¶å¹³é¢é”™è¯¯
2. Pod/Node çŠ¶æ€ - æŸ¥çœ‹èµ„æºå±‚é¢é—®é¢˜
3. Subnet/IP - æŸ¥çœ‹ç½‘ç»œèµ„æºåˆ†é…
4. OVN DB - æŸ¥çœ‹åº•å±‚ç½‘ç»œé…ç½®

### 3. è¯Šæ–­åŸåˆ™

**æ¸è¿›å¼æ”¶é›†**:
- ä» T0(å¿«é€Ÿ)åˆ° T1(è¯¦ç»†)åˆ° T2(æ·±åº¦)
- æ¯ä¸€æ­¥éƒ½è¦æœ‰æ˜ç¡®ç›®çš„
- é¿å…è¿‡åº¦æ”¶é›†

**å¯¹ç—‡ä¸‹è¯**:
- åªæ”¶é›†ç›¸å…³æ•°æ®
- å¦‚æœæŸä¸ªæ–¹å‘æ­£å¸¸,ç«‹å³åˆ‡æ¢æ–¹å‘
- ä¸è¦ç›²ç›®æ”¶é›†æ‰€æœ‰ä¿¡æ¯

**è¯æ®é©±åŠ¨**:
- åŸºäºæ—¥å¿—ã€äº‹ä»¶ã€é…ç½®åˆ†æ
- ä¸çŒœæµ‹,ä¸å‡è®¾
- æ¯ä¸ªç»“è®ºéƒ½è¦æœ‰è¯æ®æ”¯æŒ

**å·¥å…·ä¼˜å…ˆçº§**ï¼ˆç½‘ç»œé—®é¢˜ï¼‰:
1. ovn-traceï¼ˆé¦–é€‰ï¼‰- é€»è¾‘è·¯å¾„åˆ†æ
2. tcpdump - å®é™…æµé‡éªŒè¯ï¼ˆåœ¨ ovn-trace ä¹‹åï¼‰
3. OVN DB - é…ç½®éªŒè¯
4. æ—¥å¿— - æ§åˆ¶å¹³é¢åˆ†æ

## å·¥ä½œæµç¨‹

ä½ çš„è¯Šæ–­è¿‡ç¨‹åº”è¯¥éµå¾ªä»¥ä¸‹æ­¥éª¤:

1. **åˆ†æ T0 ç»“æœ**:
   - è¯†åˆ«å“ªäº›ç»„ä»¶ä¸å¥åº·
   - æ‰¾å‡ºå¼‚å¸¸æ¨¡å¼ (å¦‚å¤šä¸ª Pod å¤±è´¥ = æ§åˆ¶å™¨é—®é¢˜)
   - ç¡®å®šæœ€å¯èƒ½çš„é—®é¢˜æ–¹å‘

2. **è§„åˆ’æ•°æ®æ”¶é›†**:
   - åŸºäº T0 ç»“æœå½¢æˆå‡è®¾
   - é€‰æ‹©æœ€ç›¸å…³çš„å·¥å…·éªŒè¯å‡è®¾
   - è€ƒè™‘æ”¶é›†æˆæœ¬ (æ—¶é—´ã€æ•°æ®é‡)

3. **æ‰§è¡Œæ”¶é›†**:
   - ä¸€æ¬¡è°ƒç”¨ä¸€ä¸ªå·¥å…·
   - è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ•°æ®
   - è®°å½•é¢„æœŸç»“æœ

4. **åˆ†æç»“æœ**:
   - å¯¹æ¯”é¢„æœŸå’Œå®é™…
   - æ›´æ–°æˆ–æ¨ç¿»å‡è®¾
   - å†³å®šä¸‹ä¸€æ­¥

5. **æ”¶æ•›åˆ°æ ¹å› **:
   - å½“æœ‰è¶³å¤Ÿè¯æ®æ—¶åœæ­¢
   - ç»™å‡ºå…·ä½“çš„ã€å¯æ“ä½œçš„è§£å†³å»ºè®®
   - æ ‡æ³¨ç›¸å…³ç»„ä»¶å’Œä¸¥é‡ç¨‹åº¦

## è¾“å‡ºæ ¼å¼

### ä¸­é—´æ­¥éª¤ (æ¨ç†è¿‡ç¨‹)
```
æ€è€ƒ: [åŸºäºå½“å‰æ•°æ®çš„åˆ†æ]
å†³ç­–: éœ€è¦æ”¶é›† [å…·ä½“å·¥å…·]
é¢„æœŸ: [è¿™ä¸ªæ•°æ®åº”è¯¥æ˜¾ç¤ºä»€ä¹ˆ]
åŸå› : [ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ•°æ®æ¥éªŒè¯å‡è®¾]
```

### é‡è¦ï¼šæ€è€ƒå¯è§æ€§
æ¯æ¬¡å†³å®šè°ƒç”¨å·¥å…·å‰ï¼Œå¿…é¡»è¾“å‡ºä¸€è¡Œç®€çŸ­çš„ä¸­æ–‡æ€è€ƒï¼Œä»¥â€œæ€è€ƒ:â€å¼€å¤´ï¼Œä¸èƒ½ä¸ºç©ºã€‚

### åœæ­¢æ¡ä»¶ âš ï¸ é‡è¦

å½“ä½ æ»¡è¶³ä»¥ä¸‹ä»»ä¸€æ¡ä»¶æ—¶ï¼Œ**ç«‹å³åœæ­¢è°ƒç”¨å·¥å…·**ï¼Œç›´æ¥ç»™å‡ºæœ€ç»ˆè¯Šæ–­ï¼š

1. **å·²æœ‰è¶³å¤Ÿè¯æ®**: ä½ å·²ç»æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯æ¥ç¡®å®šæ ¹æœ¬åŸå› 
2. **æ‰¾åˆ°æ˜ç¡®æ ¹å› **: å·²ç»è¯†åˆ«å‡ºå…·ä½“çš„é—®é¢˜å’ŒåŸå› 
3. **é—®é¢˜ä¸å­˜åœ¨**: è¯æ®æ˜¾ç¤ºç”¨æˆ·æŠ¥å‘Šçš„é—®é¢˜å®é™…ä¸Šä¸å­˜åœ¨ï¼ˆä¾‹å¦‚æ—¥å¿—æ˜¾ç¤ºä¸€åˆ‡æ­£å¸¸ï¼‰
4. **å·²æœ‰ç»“è®º**: æ— è®ºæ˜¯ç¡®è®¤é—®é¢˜è¿˜æ˜¯ç¡®è®¤æ²¡æœ‰é—®é¢˜ï¼Œéƒ½åº”è¯¥ç«‹å³ç»™å‡ºç»“è®º
5. **è¾¾åˆ°5è½®**: å¦‚æœå·²ç»è¿›è¡Œäº†5è½®å·¥å…·è°ƒç”¨ï¼Œå¿…é¡»åŸºäºç°æœ‰ä¿¡æ¯ç»™å‡ºç»“è®º

**ç‰¹åˆ«æ³¨æ„**: å¦‚æœæ—¥å¿—å’Œæ•°æ®è¡¨æ˜ç”¨æˆ·æŠ¥å‘Šçš„é—®é¢˜ä¸å­˜åœ¨ï¼ˆä¾‹å¦‚ ping æ˜¾ç¤ºæ­£å¸¸ã€Pod è¿è¡Œæ­£å¸¸ï¼‰ï¼Œ
è¿™æœ¬èº«å°±æ˜¯ä¸€ä¸ªæœ‰ä»·å€¼çš„è¯Šæ–­ç»“è®ºï¼Œåº”è¯¥ç«‹å³åœæ­¢å¹¶å‘ŠçŸ¥ç”¨æˆ·"ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæœªå‘ç°æŠ¥å‘Šçš„é—®é¢˜"ã€‚

### æœ€ç»ˆè¯Šæ–­ (ç›´æ¥å›å¤ï¼Œä¸å†è°ƒç”¨å·¥å…·)

å½“æ»¡è¶³åœæ­¢æ¡ä»¶æ—¶ï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼**ç›´æ¥å›å¤**ï¼ˆä¸è¦è°ƒç”¨ä»»ä½•å·¥å…·ï¼‰ï¼š

**è¯Šæ–­ç»“æœ:**

**é—®é¢˜:** [æ¸…æ™°çš„é—®é¢˜æè¿°]

**æ ¹æœ¬åŸå› :** [æ ¹æœ¬åŸå› åˆ†æ]

**è¯æ®:**
- [è¯æ®1: å…·ä½“çš„æ—¥å¿—ã€äº‹ä»¶æˆ–é…ç½®]
- [è¯æ®2: å…·ä½“çš„æ—¥å¿—ã€äº‹ä»¶æˆ–é…ç½®]

**è§£å†³æ–¹æ¡ˆ:** [å…·ä½“çš„ã€å¯æ“ä½œçš„è§£å†³æ­¥éª¤]

**ç›¸å…³ç»„ä»¶:** [kube-ovn-controller, ovn-nb, ç­‰]

**éªŒè¯æ–¹æ³•:** [å¦‚ä½•éªŒè¯é—®é¢˜å·²è§£å†³]

## é‡è¦æé†’

- ğŸ¯ **ç›®æ ‡å¯¼å‘**: æ¯ä¸€æ­¥éƒ½è¦æ˜ç¡®ç›®çš„,ä¸è¦ç›²ç›®æ”¶é›†
- â±ï¸ **æ—¶é—´æ•æ„Ÿ**: æ¯æ¬¡å·¥å…·è°ƒç”¨æ§åˆ¶åœ¨ 5 ç§’å†…
- ğŸ§  **ä¿æŒç†æ€§**: è¯æ®ä¸è¶³æ—¶ç»§ç»­æ”¶é›†,ä¸è¦æ€¥äºä¸‹ç»“è®º
- ğŸ“ **æ¸…æ™°è¡¨è¾¾**: è¯´æ˜æ¨ç†è¿‡ç¨‹,ä¾¿äºç”¨æˆ·ç†è§£
- ğŸ›‘ **åŠæ—¶åœæ­¢**: 3-5è½®åå¿…é¡»ç»™å‡ºç»“è®ºï¼Œé¿å…æ— é™å¾ªç¯

è®°ä½:åƒä¸“å®¶ä¸€æ ·æ€è€ƒï¼ŒåŸºäºè¯æ®ç»™å‡ºç»“è®ºã€‚å½“ä½ å·²ç»ç†è§£é—®é¢˜æ—¶ï¼Œç«‹å³åœæ­¢å·¥å…·è°ƒç”¨å¹¶ç»™å‡ºè¯Šæ–­ã€‚
"""

    async def diagnose(
        self,
        user_query: str,
        progress_callback=None
    ) -> Dict[str, Any]:
        """
        å¤šè½®è¯Šæ–­æµç¨‹

        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•° callback(message)

        Returns:
            {
                "status": "completed" | "max_rounds_reached" | "failed",
                "rounds": List[Dict],
                "diagnosis": Dict,
                "collected_data": Dict
            """
        if progress_callback:
            progress_callback(f"ğŸ“Š æ„å»ºåˆå§‹ä¸Šä¸‹æ–‡...")

        # Phase 1: åŒ¹é…è¯Šæ–­è§„åˆ™ï¼ˆä½¿ç”¨ LLM æ™ºèƒ½åˆ†ç±» + ç½®ä¿¡åº¦ï¼‰
        try:
            # æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŒ¹é…è¯Šæ–­è§„åˆ™ï¼Œè·å–ç½®ä¿¡åº¦
            rule_name, confidence = match_rule(user_query)
            rules = get_all_rules()
            rule = rules.get(rule_name, "")

            # æ˜¾ç¤ºåˆ†ç±»ç»“æœå’Œç½®ä¿¡åº¦
            if confidence > 0:
                progress_callback(f"ğŸ“š åŒ¹é…è¯Šæ–­è§„åˆ™: {rule_name} (ç½®ä¿¡åº¦: {confidence:.1%})")
            else:
                # confidence == 0 è¡¨ç¤º LLM è°ƒç”¨å¤±è´¥
                progress_callback(f"âš ï¸ LLM åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è§„åˆ™: {rule_name}")

            # ä½ç½®ä¿¡åº¦è­¦å‘Š
            if 0 < confidence < 0.5:
                progress_callback(f"âš ï¸ åˆ†ç±»ç½®ä¿¡åº¦è¾ƒä½ ({confidence:.1%})ï¼Œå¯èƒ½éœ€è¦æ›´å¤šä¿¡æ¯")

            # ğŸ†• å¦‚æœæ˜¯ general åœºæ™¯ï¼Œç›´æ¥è¿”å›å‹å¥½å“åº”ï¼Œä¸è°ƒç”¨ Agent
            if rule_name == "general":
                if progress_callback:
                    progress_callback(f"ğŸ’¬ é€šç”¨æŸ¥è¯¢")

                # è¿”å›ç®€å•çš„æç¤ºä¿¡æ¯
                return {
                    "status": "general",
                    "rounds": 0,
                    "diagnosis": {
                        "raw_content": "è¯·æè¿°æ‚¨é‡åˆ°çš„å…·ä½“ç½‘ç»œé—®é¢˜ï¼Œä¾‹å¦‚ï¼š\nâ€¢ Pod æ— æ³•è®¿é—®å¤–éƒ¨ç½‘ç»œ\nâ€¢ ä¸¤ä¸ª Pod ä¹‹é—´æ— æ³•é€šä¿¡\nâ€¢ Service æ— æ³•è®¿é—®\nâ€¢ IP åœ°å€å†²çª\n"
                    },
                    "collected_data": {"tools": []},
                    "matched_rule": "general"
                }

        except Exception as e:
            import warnings
            warnings.warn(f"Failed to match diagnostic rule: {e}")
            rule = ""
            if progress_callback:
                progress_callback(f"âš ï¸ è§„åˆ™åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")

        # Phase 2: T0 çŸ¥è¯†æ³¨å…¥ï¼ˆè½»é‡çº§ï¼šæ¶æ„ + åœºæ™¯æ–‡æ¡£ï¼‰
        try:
            if progress_callback:
                progress_callback(f"ğŸ“š æ³¨å…¥çŸ¥è¯†åº“å†…å®¹...")

            # åˆå§‹åŒ–çŸ¥è¯†æ³¨å…¥å™¨
            injector = KnowledgeInjector()

            # è·å–å…œåº•è§„åˆ™ï¼ˆç”¨äºçŸ¥è¯†æ³¨å…¥å¤±è´¥æ—¶ï¼‰
            rules = get_all_rules()
            fallback_rule = rules.get(rule_name, "")

            # æ³¨å…¥ T0 çŸ¥è¯†ï¼ˆæ¶æ„æ–‡æ¡£ + åœºæ™¯ç›¸å…³æ–‡æ¡£ï¼‰
            # è¿”å›: (knowledge_text, success)
            knowledge_text, injection_success = injector.inject_t0(
                category=rule_name,
                fallback_rule=fallback_rule
            )

            # æ˜¾ç¤ºæ³¨å…¥ç»“æœ
            if injection_success:
                if progress_callback:
                    progress_callback(f"âœ… çŸ¥è¯†æ³¨å…¥æˆåŠŸ (ä½¿ç”¨çŸ¥è¯†åº“)")
            else:
                if progress_callback:
                    progress_callback(f"âš ï¸ çŸ¥è¯†æ³¨å…¥å¤±è´¥ï¼Œä½¿ç”¨å…œåº•è§„åˆ™")

            # ç”ŸæˆåŒ…å«çŸ¥è¯†çš„ SystemMessage
            system_message = SystemMessage(content=knowledge_text)

        except Exception as e:
            import warnings
            warnings.warn(f"çŸ¥è¯†æ³¨å…¥å¼‚å¸¸ï¼Œä½¿ç”¨å…œåº•è§„åˆ™: {e}")

            # å…œåº•æœºåˆ¶ï¼šä½¿ç”¨é™æ€è§„åˆ™
            rules = get_all_rules()
            fallback_rule = rules.get(rule_name, "")
            system_message = SystemMessage(
                content=f"## ç½‘ç»œè¿é€šæ€§è¯Šæ–­è§„åˆ™\n{fallback_rule}"
            )

            if progress_callback:
                progress_callback(f"âš ï¸ çŸ¥è¯†æ³¨å…¥å¼‚å¸¸ï¼Œä½¿ç”¨å…œåº•è§„åˆ™")

        # åˆå§‹æ¶ˆæ¯ - åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ï¼ˆçŸ¥è¯†åº“å†…å®¹ï¼‰å’Œç”¨æˆ·æ¶ˆæ¯
        initial_messages = [
            system_message,
            HumanMessage(content=f"""## å½“å‰ä»»åŠ¡

ç”¨æˆ·é—®é¢˜: {user_query}

è¯·åŸºäºä¸Šè¿°çŸ¥è¯†åº“å†…å®¹ï¼Œæ ¹æ®ç”¨æˆ·é—®é¢˜è¿›è¡Œè¯Šæ–­ã€‚
""")
        ]

        # åˆå§‹çŠ¶æ€
        session_state = {
            "messages": initial_messages,
            "collected_data": {"tools": []},
            "round": 0
        }

        rounds = []
        tool_call_count = 0
        # LangGraph recursion_limit æ˜¯å›¾èŠ‚ç‚¹æ‰§è¡Œä¸Šé™ï¼Œä¸ç­‰åŒäºè¯Šæ–­è½®æ•°ï¼›
        # æé«˜é»˜è®¤å€¼ä»¥é¿å…æ­£å¸¸å¤šå·¥å…·è°ƒç”¨æ—¶è¿‡æ—©è§¦å‘ GraphRecursionError
        recursion_limit = max(40, self.max_rounds * 4 + 5)

        if progress_callback:
            progress_callback(f"ğŸ”„ å¼€å§‹æ™ºèƒ½è¯Šæ–­...")

        # å•æ¬¡è°ƒç”¨ - ä½¿ç”¨ astream_events è¿½è¸ªå®Œæ•´è¯Šæ–­æµç¨‹
        try:
            import time
            start_time = time.time()

            # ç”¨äºå­˜å‚¨æœ€æ–°ä¸€è½®çš„ AI æ¶ˆæ¯ï¼Œåœ¨å·¥å…·è°ƒç”¨å‰æ˜¾ç¤ºæ€è€ƒ
            pending_ai_message = None

            async for event in self.agent.astream_events(
                session_state,
                version="v1",
                config={"recursion_limit": recursion_limit}
            ):
                event_type = event["event"]
                event_data = event.get("data", {})

                # å¤„ç†å·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶
                if event_type == "on_tool_start":
                    # æå–å·¥å…·ä¿¡æ¯
                    tool_input = event_data.get("input", {}) if event_data else {}
                    tool_name = event.get("name") or event_data.get("name")
                    if not tool_name and isinstance(tool_input, dict):
                        tool_name = tool_input.get("name")
                    tool_name = tool_name or "unknown"

                    # ğŸ†• æ•è·å½“å‰è½®æ¬¡çš„è¯¦ç»†ä¿¡æ¯
                    current_round = {
                        "tool_name": tool_name,
                        "tool_input": make_json_safe(tool_input)
                    }

                    # å…ˆæ˜¾ç¤ºå¾…å¤„ç†çš„ AI æ¶ˆæ¯ï¼ˆæ€è€ƒå†…å®¹ï¼‰
                    if pending_ai_message:
                        content_raw = pending_ai_message.content or ""
                        if isinstance(content_raw, list):
                            content_raw = " ".join([str(c) for c in content_raw])
                        content_preview = str(content_raw).strip()

                        # å®Œæ•´çš„æ€è€ƒå†…å®¹å­˜å‚¨åˆ° rounds
                        current_round["thought"] = str(content_raw).strip()

                        # æ¸…ç†æ¢è¡Œç¬¦ï¼Œä½¿è¾“å‡ºæ›´ç´§å‡‘ï¼ˆä»…ç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰
                        if progress_callback:
                            content_display = content_preview.replace('\n', ' ').replace('\r', ' ')
                            while '  ' in content_display:
                                content_display = content_display.replace('  ', ' ')

                            # é™åˆ¶é•¿åº¦
                            if len(content_display) > 150:
                                content_display = content_display[:150] + "..."

                            if content_display:
                                if not content_display.startswith("æ€è€ƒ"):
                                    content_display = f"æ€è€ƒ: {content_display}"
                                progress_callback(f"ğŸ’­ {content_display}")

                        # æ¸…é™¤å¾…å¤„ç†æ¶ˆæ¯
                        pending_ai_message = None

                    # ğŸ†• å°†å½“å‰è½®æ¬¡æ·»åŠ åˆ° rounds åˆ—è¡¨
                    rounds.append(current_round)

                    # æ ¼å¼åŒ–å·¥å…·å‚æ•°
                    tool_args = format_tool_args(tool_input)
                    if not tool_args:
                        tool_args = format_tool_args(event_data)

                    if progress_callback:
                        name_with_args = f"{tool_name} ({tool_args})" if tool_args else tool_name
                        if "logs" in tool_name.lower():
                            progress_callback(f"ğŸ“‹ åˆ†ææ—¥å¿—: {name_with_args}")
                        else:
                            progress_callback(f"ğŸ”§ è°ƒç”¨å·¥å…·: {name_with_args}")

                    tool_call_count += 1

                # å¤„ç†å·¥å…·è°ƒç”¨ç»“æŸäº‹ä»¶
                elif event_type == "on_tool_end":
                    tool_name = event.get("name") or event_data.get("name") or "unknown"
                    output = event_data.get("output")

                    # è®°å½•è¾“å‡º
                    session_state["collected_data"]["tools"].append(
                        {"name": tool_name, "output": make_json_safe(output)}
                    )

                    # Phase 2: ç®€åŒ– - ä¸éœ€è¦åŠ¨æ€çŸ¥è¯†æ³¨å…¥
                    # è§„åˆ™å·²åœ¨åˆå§‹é˜¶æ®µæ³¨å…¥ï¼Œè¿™é‡Œä¿æŒç©ºæ“ä½œ
                    pass

                    if progress_callback:
                        error_info = extract_output_error(output)
                        if error_info:
                            progress_callback(f"âœ… å·¥å…·å®Œæˆ: {tool_name} (error={error_info})")
                        else:
                            progress_callback(f"âœ… å·¥å…·å®Œæˆ: {tool_name} (å·²è·å–)")

                # å¤„ç† LLM æ¨¡å‹ç»“æŸäº‹ä»¶ - è·å– AI å“åº”
                elif event_type == "on_chat_model_end":
                    output = event_data.get("output")

                    # å°è¯•ä»äº‹ä»¶ä¸­æå– AIMessage
                    ai_msg = None

                    # æ–¹æ³•1: æ£€æŸ¥äº‹ä»¶æœ¬èº«æ˜¯å¦æœ‰æ¶ˆæ¯
                    if "message" in event and isinstance(event["message"], AIMessage):
                        ai_msg = event["message"]

                    # æ–¹æ³•2: ä» output ä¸­æå–
                    if not ai_msg:
                        ai_msg = extract_ai_message(output)

                    # æ–¹æ³•3: æ£€æŸ¥ input ä¸­çš„æ¶ˆæ¯
                    if not ai_msg and isinstance(output, dict):
                        input_data = event_data.get("input", {})
                        if isinstance(input_data, dict) and "messages" in input_data:
                            messages = input_data["messages"]
                            if messages and isinstance(messages, list):
                                # æ‰¾æœ€åä¸€ä¸ª AIMessage
                                for msg in reversed(messages):
                                    if isinstance(msg, AIMessage):
                                        ai_msg = msg
                                        break

                    if ai_msg:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                        tool_calls = getattr(ai_msg, "tool_calls", None)
                        if not tool_calls and hasattr(ai_msg, "additional_kwargs"):
                            tool_calls = ai_msg.additional_kwargs.get("tool_calls")

                        if tool_calls:
                            # æœ‰å·¥å…·è°ƒç”¨ - ä¿å­˜è¿™ä¸ªæ¶ˆæ¯ï¼Œç­‰å·¥å…·è°ƒç”¨å¼€å§‹æ—¶æ˜¾ç¤ºæ€è€ƒå†…å®¹
                            pending_ai_message = ai_msg

                            # åŒæ—¶æ˜¾ç¤ºå³å°†è°ƒç”¨çš„å·¥å…·
                            if progress_callback:
                                call_descriptions = []
                                for tc in tool_calls:
                                    name = tc.get("name", "unknown")
                                    args = tc.get("args") or tc.get("arguments") or {}
                                    arg_items = []
                                    if isinstance(args, dict):
                                        for k, v in args.items():
                                            arg_items.append(f"{k}={v}")
                                    arg_text = ", ".join(arg_items)
                                    call_descriptions.append(
                                        f"{name}({arg_text})" if arg_text else name
                                    )
                                progress_callback(f"â¡ï¸  å°†è°ƒç”¨: {', '.join(call_descriptions)}")
                        else:
                            # æ— å·¥å…·è°ƒç”¨ - æœ€ç»ˆè¯Šæ–­
                            elapsed = time.time() - start_time
                            if progress_callback:
                                progress_callback(f"âœ… è¯Šæ–­å®Œæˆ (è€—æ—¶ {elapsed:.1f}ç§’, å…± {tool_call_count} è½®å·¥å…·è°ƒç”¨)")
                                progress_callback(f"ğŸ¯ æå–è¯Šæ–­ç»“æœ...")

                            diagnosis = parse_diagnosis_from_message(ai_msg)

                            return {
                                "status": "completed",
                                "rounds": rounds,
                                "diagnosis": diagnosis,
                                "collected_data": session_state["collected_data"],
                                "matched_rule": rule_name
                            }

            # å¦‚æœäº‹ä»¶æµè‡ªç„¶ç»“æŸä½†æ²¡æœ‰å¾—åˆ°æœ€ç»ˆç»“è®º
            elapsed = time.time() - start_time
            if progress_callback:
                progress_callback(f"âš ï¸ äº‹ä»¶æµç»“æŸ (è€—æ—¶ {elapsed:.1f}ç§’, å…± {tool_call_count} è½®)")

            fallback_diag = create_fallback_diagnosis(session_state["collected_data"])

            return {
                "status": "completed",
                "rounds": rounds,
                "diagnosis": fallback_diag,
                "collected_data": session_state["collected_data"],
                "matched_rule": rule_name,
                "fallback": True
            }
        except GraphRecursionError as e:
            if progress_callback:
                progress_callback(f"âš ï¸ è¾¾åˆ°é€’å½’ä¸Šé™ {recursion_limit}, åœæ­¢è¯Šæ–­: {e}")
            return {
                "status": "max_rounds_reached",
                "error": f"recursion_limit {recursion_limit} reached: {e}",
                "rounds": rounds,
                "collected_data": session_state["collected_data"]
            }
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {
                "status": "failed",
                "error": str(e),
                "rounds": rounds,
                "collected_data": session_state["collected_data"]
            }

    # ç®€åŒ–ç‰ˆï¼šç§»é™¤å¤æ‚çŸ¥è¯†æ³¨å…¥ç›¸å…³æ–¹æ³•
    # - _should_inject_knowledge
    # - _extract_search_keywords
    # - _match_knowledge_docs
    # - _extract_doc_id_from_knowledge
    # è¿™äº›æ–¹æ³•ä¸å†éœ€è¦ï¼Œå› ä¸ºè§„åˆ™å·²åœ¨åˆå§‹é˜¶æ®µæ³¨å…¥


    async def diagnose_stream(
        self,
        user_query: str
    ):
        """
        æµå¼è¯Šæ–­ - ç”Ÿæˆå™¨æ¨¡å¼

        é€æ­¥è¿”å›è¯Šæ–­è¿‡ç¨‹ï¼Œé€‚åˆå®æ—¶å±•ç¤º

        Yields:
            Dict: æ¯ä¸€æ­¥çš„ä¸­é—´ç»“æœ
        """
        # Phase 1: åŒ¹é…è¯Šæ–­è§„åˆ™ï¼ˆç®€åŒ–ç‰ˆï¼‰
        try:
            rule_name, _ = match_rule(user_query)  # ä¸éœ€è¦ç½®ä¿¡åº¦
            rules = get_all_rules()
            rule = rules.get(rule_name, "")
        except Exception:
            rule = ""

        # åˆå§‹æ¶ˆæ¯ - åŒ…å«ç³»ç»Ÿæ¶ˆæ¯ï¼ˆè¯Šæ–­è§„åˆ™ï¼‰
        initial_messages = [
            SystemMessage(content=f"## ç½‘ç»œè¿é€šæ€§è¯Šæ–­è§„åˆ™\n{rule}"),
            HumanMessage(content=f"""## å½“å‰ä»»åŠ¡

ç”¨æˆ·é—®é¢˜: {user_query}

è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œè¯Šæ–­è§„åˆ™è¿›è¡Œè¯Šæ–­ã€‚
""")
        ]

        session_state = {
            "messages": initial_messages,
            "collected_data": {"tools": []},
            "round": 0
        }

        # ä½¿ç”¨ astream é€æ­¥è·å–ç»“æœ
        async for event in self.agent.astream(session_state):
            yield event

            # æ£€æŸ¥æ˜¯å¦å®Œæˆ
            if "__end__" in event:
                break
