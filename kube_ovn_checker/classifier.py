"""
æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»å™¨ - ä½¿ç”¨ LLM + Transformer çœŸå®æ¦‚ç‡

æ ¸å¿ƒè®¾è®¡ï¼š
- ä½¿ç”¨ GPT-4o-mini è¿›è¡Œåœºæ™¯åˆ†ç±»
- åŸºäº Transformer softmax æ¦‚ç‡è®¡ç®—çœŸå®ç½®ä¿¡åº¦
- æ”¯æŒ 5 ä¸ªæ ¸å¿ƒè¯Šæ–­åœºæ™¯
"""

import math
import os
from typing import List, Dict, Any
from langchain_openai import ChatOpenAI


class QueryClassification:
    """æŸ¥è¯¢åˆ†ç±»ç»“æœ

    Attributes:
        category: åˆ†ç±»ç»“æœï¼ˆåœºæ™¯åç§°ï¼‰
        confidence: ç½®ä¿¡åº¦ï¼ˆ0-1ï¼ŒåŸºäº Transformer softmax æ¦‚ç‡ï¼‰
        token_probs: æ¯ä¸ª token çš„æ¦‚ç‡è¯¦æƒ…ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    """

    def __init__(self, category: str, confidence: float, token_probs: List[Dict[str, Any]]):
        self.category = category
        self.confidence = confidence
        self.token_probs = token_probs

    def __repr__(self):
        return f"QueryClassification(category={self.category}, confidence={self.confidence:.3f})"


class IntelligentClassifier:
    """åŸºäº LLM çš„æ™ºèƒ½æŸ¥è¯¢åˆ†ç±»å™¨ï¼ˆä½¿ç”¨ Transformer çœŸå®æ¦‚ç‡ï¼‰"""

    # å®šä¹‰åœºæ™¯ç±»åˆ«
    CATEGORIES = [
        "general",                    # é—®å€™/å¸®åŠ©
        "pod_to_pod",      # åŒèŠ‚ç‚¹ Pod é€šä¿¡
        "pod_to_pod_cross_node",     # è·¨èŠ‚ç‚¹ Pod é€šä¿¡
        "pod_to_service",            # Service è®¿é—®
        "pod_to_external"            # å¤–éƒ¨ç½‘ç»œè®¿é—®
    ]

    def __init__(self, model: str = None, api_key: str = None, base_url: str = None):
        """åˆå§‹åŒ–åˆ†ç±»å™¨

        Args:
            model: LLM æ¨¡å‹åç§°ï¼ˆé»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼‰
            api_key: OpenAI API keyï¼ˆå¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            base_url: API base URLï¼ˆå¯é€‰ï¼‰
        """
        self.api_key = api_key or os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("LLM_API_BASE")

        if not self.api_key:
            raise ValueError(
                "æœªæ‰¾åˆ° API Keyã€‚è¯·è®¾ç½® LLM_API_KEY æˆ– OPENAI_API_KEY ç¯å¢ƒå˜é‡"
            )

        # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
        if model is None:
            # å¦‚æœä½¿ç”¨æ™ºè°±AI,ä½¿ç”¨ glm-4-flash
            if "bigmodel.cn" in self.base_url:
                model = "glm-4-flash"  # æ™ºè°±AI çš„å¿«é€Ÿæ¨¡å‹
            else:
                model = "gpt-4o-mini"  # OpenAI çš„é»˜è®¤æ¨¡å‹

        # ä½¿ç”¨ LangChain çš„ ChatOpenAI,å…¼å®¹æ™ºè°±AI
        llm_kwargs = {
            "model": model,
            "temperature": 0.0,
            "api_key": self.api_key
        }

        if self.base_url:
            llm_kwargs["base_url"] = self.base_url

        self.client = ChatOpenAI(**llm_kwargs)
        self.model = model

        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = f"""ä½ æ˜¯ Kube-OVN ç½‘ç»œè¯Šæ–­ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åˆ†ç±»åˆ°ä»¥ä¸‹åœºæ™¯ä¹‹ä¸€ï¼š

{', '.join(self.CATEGORIES)}

åˆ†ç±»è§„åˆ™ï¼š
1. **general** - é—®å€™è¯­ã€å¸®åŠ©è¯·æ±‚ã€éè¯Šæ–­æŸ¥è¯¢
2. **pod_to_pod** - åŒä¸€èŠ‚ç‚¹å†…çš„ Pod é€šä¿¡é—®é¢˜
3. **pod_to_pod_cross_node** - ä¸åŒèŠ‚ç‚¹çš„ Pod é€šä¿¡é—®é¢˜
4. **pod_to_service** - Kubernetes Service è®¿é—®é—®é¢˜
5. **pod_to_external** - Pod è®¿é—®å¤–éƒ¨ç½‘ç»œçš„é—®é¢˜

åªè¿”å›ç±»åˆ«åç§°ï¼Œä¸è¦è§£é‡Šã€‚"""

    def classify(self, query: str) -> QueryClassification:
        """åˆ†ç±»ç”¨æˆ·æŸ¥è¯¢ï¼ˆä½¿ç”¨ LLMï¼‰

        Args:
            query: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢

        Returns:
            QueryClassification: åŒ…å«ç±»åˆ«å’Œç½®ä¿¡åº¦

        Raises:
            Exception: LLM API è°ƒç”¨å¤±è´¥
        """
        from langchain_core.messages import HumanMessage, SystemMessage

        messages = [
            SystemMessage(content=self.system_prompt),
            HumanMessage(content=query)
        ]

        # è°ƒç”¨ LLM
        response = self.client.invoke(messages)

        # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
        if not response or not response.content:
            raise Exception("LLM API è¿”å›ç©ºå“åº”")

        # æå–åˆ†ç±»ç»“æœ
        category = response.content.strip()

        # æ³¨æ„: LangChain çš„ ChatOpenAI ä¸ç›´æ¥è¿”å› logprobs
        # æˆ‘ä»¬ä½¿ç”¨å›ºå®šçš„ç½®ä¿¡åº¦ 0.8,è¡¨ç¤º LLM æœ‰è¾ƒé«˜çš„åˆ†ç±»ç¡®å®šæ€§
        # å¦‚æœéœ€è¦æ›´ç²¾ç¡®çš„ç½®ä¿¡åº¦,å¯ä»¥:
        # 1. å¤šæ¬¡é‡‡æ ·è®¡ç®—ä¸€è‡´æ€§
        # 2. ä½¿ç”¨åŸç”Ÿ OpenAI SDK (ä½†ä¼šå¤±å»æ™ºè°±AIå…¼å®¹æ€§)
        confidence = 0.8

        return QueryClassification(
            category=category,
            confidence=confidence,
            token_probs=[]  # LangChain ä¸æä¾› token-level æ¦‚ç‡
        )

    def classify_with_fallback(self, query: str, min_confidence: float = 0.5) -> QueryClassification:
        """åˆ†ç±»å¹¶å¤„ç†ä½ç½®ä¿¡åº¦æƒ…å†µ

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            min_confidence: æœ€ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ 0.5ï¼‰

        Returns:
            QueryClassification: å¦‚æœç½®ä¿¡åº¦è¿‡ä½ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
        """
        try:
            result = self.classify(query)

            # å¦‚æœç½®ä¿¡åº¦è¿‡ä½ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
            if result.confidence < min_confidence:
                return QueryClassification(
                    category="pod_to_pod",  # é»˜è®¤åœºæ™¯
                    confidence=0.0,  # æ ‡è®°ä¸ºä½ç½®ä¿¡åº¦
                    token_probs=[]
                )

            return result

        except Exception as e:
            # LLM è°ƒç”¨å¤±è´¥ï¼Œè¿”å›é»˜è®¤åˆ†ç±»
            import warnings
            warnings.warn(f"LLM åˆ†ç±»å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯: {e}")
            return QueryClassification(
                category="pod_to_pod",
                confidence=0.0,
                token_probs=[]
            )


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # è®¾ç½® API Keyï¼ˆå¦‚æœéœ€è¦ï¼‰
    import os
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        exit(1)

    classifier = IntelligentClassifier()

    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "node1 çš„ pod æ— æ³•è®¿é—® node2 çš„ pod",
        "nginx pod æ— æ³•è¿æ¥åˆ° app pod",
        "å¤–éƒ¨ç½‘ç»œä¸é€š",
        "æ— æ³•è®¿é—® service nginx-svc",
        "ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©çš„å—ï¼Ÿ",
        "ç½‘ç»œå¥½åƒæœ‰é—®é¢˜ï¼Œæœ‰ç‚¹æ…¢",
        "kube-ovn-controller Pod ä¸€ç›´é‡å¯",
        "ä¸åŒèŠ‚ç‚¹ä¹‹é—´çš„ pod æ— æ³•é€šä¿¡"
    ]

    print("ğŸ§ª LLM åˆ†ç±»æµ‹è¯•ï¼ˆçº¯ LLMï¼Œæ— è§„åˆ™åŒ¹é…ï¼‰")
    print("=" * 70)

    for query in test_queries:
        try:
            result = classifier.classify(query)

            print(f"\nğŸ“ æŸ¥è¯¢: {query}")
            print(f"ğŸ¯ åˆ†ç±»: {result.category}")
            print(f"ğŸ“Š ç½®ä¿¡åº¦: {result.confidence:.3f} (åŸºäº {len(result.token_probs)} ä¸ª token)")

            # æ˜¾ç¤ºå‰ 2 ä¸ª token çš„æ¦‚ç‡
            if result.token_probs:
                print("   Token æ¦‚ç‡:")
                for tp in result.token_probs[:2]:
                    print(f"     '{tp.token}': {tp['probability']:.3f}")

        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")
